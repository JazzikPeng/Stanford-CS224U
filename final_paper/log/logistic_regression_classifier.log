2020-06-12 17:34:13,332 - [INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2020-06-12 17:34:13,463 - [INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
2020-06-12 17:34:13,464 - [INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2020-06-12 17:34:13,611 - [INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
2020-06-13 00:06:23,218 - [INFO] - Total loss at epoch 1: 929.47122
2020-06-13 00:06:23,218 - [INFO] - Avrg  loss at epoch 1: 0.00056
2020-06-13 03:25:16,188 - [INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2020-06-13 03:25:16,496 - [INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
2020-06-13 03:25:16,496 - [INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2020-06-13 03:25:16,652 - [INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
2020-06-13 09:56:34,175 - [INFO] - Total loss at epoch 1: 929.47122
2020-06-13 09:56:34,175 - [INFO] - Avrg  loss at epoch 1: 0.00056
2020-06-14 02:53:39,086 - [INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2020-06-14 02:53:39,311 - [INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
2020-06-14 02:53:39,312 - [INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2020-06-14 02:53:39,454 - [INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
2020-06-14 03:02:27,509 - [INFO] - Total loss at epoch 1: 35.53074
2020-06-14 03:02:27,509 - [INFO] - Avrg  loss at epoch 1: 0.00089
2020-06-14 03:10:11,291 - [INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2020-06-14 03:10:11,400 - [INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
2020-06-14 03:10:11,401 - [INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2020-06-14 03:10:11,938 - [INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
2020-06-14 03:18:53,967 - [INFO] - Total loss at epoch 1: 35.53074
2020-06-14 03:18:53,967 - [INFO] - Avrg  loss at epoch 1: 0.00089
2020-06-14 03:21:53,235 - [INFO] - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2020-06-14 03:21:53,343 - [INFO] - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
2020-06-14 03:21:53,343 - [INFO] - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2020-06-14 03:21:53,519 - [INFO] - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
2020-06-14 03:30:39,924 - [INFO] - Total loss at epoch 1: 35.53074
2020-06-14 03:30:39,924 - [INFO] - Avrg  loss at epoch 1: 0.00089
2020-06-14 03:41:47,558 - [INFO] - [F1, Accuracy] score at epoch 1 | train: (0.57238, 0.57856) | test: (0.59120, 0.59772)
2020-06-14 03:50:52,899 - [INFO] - Total loss at epoch 2: 26.00188
2020-06-14 03:50:52,900 - [INFO] - Avrg  loss at epoch 2: 0.00065
2020-06-14 04:02:14,686 - [INFO] - [F1, Accuracy] score at epoch 2 | train: (0.59553, 0.60590) | test: (0.61150, 0.62245)
2020-06-14 04:11:18,314 - [INFO] - Total loss at epoch 3: 25.61073
2020-06-14 04:11:18,314 - [INFO] - Avrg  loss at epoch 3: 0.00064
2020-06-14 04:22:41,484 - [INFO] - [F1, Accuracy] score at epoch 3 | train: (0.59287, 0.60097) | test: (0.61400, 0.62297)
2020-06-14 04:31:45,108 - [INFO] - Total loss at epoch 4: 24.99630
2020-06-14 04:31:45,108 - [INFO] - Avrg  loss at epoch 4: 0.00062
2020-06-14 04:43:06,570 - [INFO] - [F1, Accuracy] score at epoch 4 | train: (0.67036, 0.67997) | test: (0.67090, 0.68027)
2020-06-14 04:52:11,093 - [INFO] - Total loss at epoch 5: 24.55049
2020-06-14 04:52:11,094 - [INFO] - Avrg  loss at epoch 5: 0.00061
2020-06-14 05:03:30,805 - [INFO] - [F1, Accuracy] score at epoch 5 | train: (0.67143, 0.67732) | test: (0.67390, 0.67910)
2020-06-14 05:12:35,486 - [INFO] - Total loss at epoch 6: 24.15602
2020-06-14 05:12:35,486 - [INFO] - Avrg  loss at epoch 6: 0.00060
2020-06-14 05:23:55,981 - [INFO] - [F1, Accuracy] score at epoch 6 | train: (0.68382, 0.69179) | test: (0.68450, 0.69230)
2020-06-14 05:33:00,942 - [INFO] - Total loss at epoch 7: 23.97903
2020-06-14 05:33:00,942 - [INFO] - Avrg  loss at epoch 7: 0.00060
2020-06-14 05:44:22,328 - [INFO] - [F1, Accuracy] score at epoch 7 | train: (0.68536, 0.70039) | test: (0.68570, 0.70078)
2020-06-14 05:53:25,792 - [INFO] - Total loss at epoch 8: 23.76751
2020-06-14 05:53:25,792 - [INFO] - Avrg  loss at epoch 8: 0.00059
2020-06-14 06:04:47,149 - [INFO] - [F1, Accuracy] score at epoch 8 | train: (0.69628, 0.70454) | test: (0.69710, 0.70517)
2020-06-14 06:13:51,397 - [INFO] - Total loss at epoch 9: 23.48889
2020-06-14 06:13:51,397 - [INFO] - Avrg  loss at epoch 9: 0.00059
2020-06-14 06:25:12,491 - [INFO] - [F1, Accuracy] score at epoch 9 | train: (0.48871, 0.49639) | test: (0.57470, 0.57688)
2020-06-14 06:34:15,598 - [INFO] - Total loss at epoch 10: 23.95247
2020-06-14 06:34:15,598 - [INFO] - Avrg  loss at epoch 10: 0.00060
2020-06-14 06:45:35,843 - [INFO] - [F1, Accuracy] score at epoch 10 | train: (0.69470, 0.69660) | test: (0.69540, 0.69695)
2020-06-14 06:54:39,274 - [INFO] - Total loss at epoch 11: 23.13472
2020-06-14 06:54:39,274 - [INFO] - Avrg  loss at epoch 11: 0.00058
2020-06-14 07:05:59,182 - [INFO] - [F1, Accuracy] score at epoch 11 | train: (0.62254, 0.62992) | test: (0.65190, 0.65620)
2020-06-14 07:15:01,442 - [INFO] - Total loss at epoch 12: 22.86577
2020-06-14 07:15:01,442 - [INFO] - Avrg  loss at epoch 12: 0.00057
2020-06-14 07:26:20,593 - [INFO] - [F1, Accuracy] score at epoch 12 | train: (0.70148, 0.71459) | test: (0.70260, 0.71572)
2020-06-14 07:35:23,159 - [INFO] - Total loss at epoch 13: 22.58008
2020-06-14 07:35:23,159 - [INFO] - Avrg  loss at epoch 13: 0.00056
2020-06-14 07:46:41,196 - [INFO] - [F1, Accuracy] score at epoch 13 | train: (0.54250, 0.54968) | test: (0.60540, 0.60782)
2020-06-14 07:55:39,787 - [INFO] - Total loss at epoch 14: 23.15896
2020-06-14 07:55:39,787 - [INFO] - Avrg  loss at epoch 14: 0.00058
2020-06-14 08:06:56,038 - [INFO] - [F1, Accuracy] score at epoch 14 | train: (0.70888, 0.71914) | test: (0.71090, 0.72080)
2020-06-14 08:15:55,045 - [INFO] - Total loss at epoch 15: 22.68383
2020-06-14 08:15:55,045 - [INFO] - Avrg  loss at epoch 15: 0.00057
2020-06-14 08:27:09,948 - [INFO] - [F1, Accuracy] score at epoch 15 | train: (0.68335, 0.68928) | test: (0.68730, 0.69370)
2020-06-14 08:36:09,302 - [INFO] - Total loss at epoch 16: 22.55721
2020-06-14 08:36:09,302 - [INFO] - Avrg  loss at epoch 16: 0.00056
2020-06-14 08:47:23,856 - [INFO] - [F1, Accuracy] score at epoch 16 | train: (0.71300, 0.72383) | test: (0.71360, 0.72452)
2020-06-14 08:56:22,453 - [INFO] - Total loss at epoch 17: 22.53661
2020-06-14 08:56:22,454 - [INFO] - Avrg  loss at epoch 17: 0.00056
2020-06-14 09:07:42,285 - [INFO] - [F1, Accuracy] score at epoch 17 | train: (0.72258, 0.72969) | test: (0.72260, 0.72975)
2020-06-14 09:16:44,281 - [INFO] - Total loss at epoch 18: 22.17224
2020-06-14 09:16:44,281 - [INFO] - Avrg  loss at epoch 18: 0.00055
2020-06-14 09:28:00,754 - [INFO] - [F1, Accuracy] score at epoch 18 | train: (0.67626, 0.68691) | test: (0.68330, 0.69398)
2020-06-14 09:36:58,679 - [INFO] - Total loss at epoch 19: 22.68706
2020-06-14 09:36:58,680 - [INFO] - Avrg  loss at epoch 19: 0.00057
2020-06-14 09:48:12,365 - [INFO] - [F1, Accuracy] score at epoch 19 | train: (0.71630, 0.72120) | test: (0.71630, 0.72127)
2020-06-14 09:57:09,476 - [INFO] - Total loss at epoch 20: 22.03232
2020-06-14 09:57:09,476 - [INFO] - Avrg  loss at epoch 20: 0.00055
2020-06-14 10:08:27,760 - [INFO] - [F1, Accuracy] score at epoch 20 | train: (0.63911, 0.64507) | test: (0.65950, 0.66622)
